{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "896647b1",
   "metadata": {},
   "source": [
    "# LoRA ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë¶„ì„\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ë² ì´ìŠ¤ ëª¨ë¸ê³¼ LoRA ê°€ì¤‘ì¹˜ë¥¼ ë¡œë”©í•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ì—¬ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "## ê¸°ëŠ¥\n",
    "- ë² ì´ìŠ¤ ëª¨ë¸ (SD/SDXL) ì´ë¯¸ì§€ ìƒì„±\n",
    "- LoRA ê°€ì¤‘ì¹˜ë¥¼ ë¡œë”©í•œ ëª¨ë¸ ì´ë¯¸ì§€ ìƒì„±\n",
    "- ë‘ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ë‚˜ë€íˆ ë¹„êµ\n",
    "- ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ë¡œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n",
    "- íŒŒë¼ë¯¸í„° ì¡°ì • ì‹¤í—˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d43b58c",
   "metadata": {},
   "source": [
    "## 1. ëª¨ë¸ ë¡œë”©\n",
    "\n",
    "ë¨¼ì € ë² ì´ìŠ¤ ëª¨ë¸ê³¼ LoRA ëª¨ë¸ì„ ë¡œë”©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1741a5a",
   "metadata": {},
   "source": [
    "## 2. ê¸°ë³¸ ì„±ëŠ¥ ë¹„êµ\n",
    "\n",
    "ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ë¡œ ë² ì´ìŠ¤ ëª¨ë¸ê³¼ LoRA ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµí•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e8fc33",
   "metadata": {},
   "source": [
    "## 3. ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ë¡œ ì„±ëŠ¥ ë¹„êµ\n",
    "\n",
    "ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ë¡œ ì„±ëŠ¥ì„ ë¹„êµí•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f83903",
   "metadata": {},
   "source": [
    "## 4. íŒŒë¼ë¯¸í„° ì‹¤í—˜\n",
    "\n",
    "ë‹¤ì–‘í•œ íŒŒë¼ë¯¸í„°ë¡œ LoRA ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì‹¤í—˜í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3423e",
   "metadata": {},
   "source": [
    "## 5. ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ ì‹¤í—˜\n",
    "\n",
    "ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ í’ˆì§ˆì„ ê°œì„ í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e8473e",
   "metadata": {},
   "source": [
    "## 6. ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ì›í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì§ì ‘ ì…ë ¥í•˜ì—¬ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae015a58",
   "metadata": {},
   "source": [
    "## 7. ì„±ëŠ¥ ë¶„ì„ ìš”ì•½\n",
    "\n",
    "í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ LoRA ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aecf769",
   "metadata": {},
   "source": [
    "## 8. ì´ë¯¸ì§€ ì €ì¥\n",
    "\n",
    "ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ae2d03",
   "metadata": {},
   "source": [
    "## ğŸ‰ ì™„ë£Œ!\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì„ í†µí•´ ë‹¤ìŒì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. âœ… **ë² ì´ìŠ¤ ëª¨ë¸ê³¼ LoRA ëª¨ë¸ ë¡œë”©**\n",
    "2. âœ… **ê¸°ë³¸ ì„±ëŠ¥ ë¹„êµ**\n",
    "3. âœ… **ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ë¡œ í…ŒìŠ¤íŠ¸**\n",
    "4. âœ… **íŒŒë¼ë¯¸í„° ì‹¤í—˜ (Guidance Scale, Cross Attention Scale)**\n",
    "5. âœ… **ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ ì‹¤í—˜**\n",
    "6. âœ… **ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸**\n",
    "7. âœ… **ì„±ëŠ¥ ë¶„ì„ ë° ìš”ì•½**\n",
    "8. âœ… **ì´ë¯¸ì§€ ì €ì¥**\n",
    "\n",
    "### ë‹¤ìŒ ë‹¨ê³„:\n",
    "- ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ë¡œ ì¶”ê°€ ì‹¤í—˜\n",
    "- ìµœì  íŒŒë¼ë¯¸í„° ì¡°í•© ì°¾ê¸°\n",
    "- ë‹¤ë¥¸ LoRA ëª¨ë¸ê³¼ ë¹„êµ\n",
    "- SageMaker ì—”ë“œí¬ì¸íŠ¸ ë°°í¬ ë° í…ŒìŠ¤íŠ¸\n",
    "\n",
    "**LoRA ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ í›ˆë ¨ë˜ì—ˆìœ¼ë©°, ë² ì´ìŠ¤ ëª¨ë¸ ëŒ€ë¹„ íŠ¹í™”ëœ ìŠ¤íƒ€ì¼ì„ ìƒì„±í•˜ëŠ” ê²ƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤!** ğŸ¨âœ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be9c369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from enum import Enum\n",
    "from typing import Any, Dict, Final, List, Tuple\n",
    "from diffusers import StableDiffusionPipeline, DiffusionPipeline, EulerDiscreteScheduler\n",
    "from diffusers.models import AutoencoderKL\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì • (ì„ íƒì‚¬í•­)\n",
    "plt.rcParams['font.family'] = ['DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5f05a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ID ì •ì˜ (test_lora_local.pyì™€ ë™ì¼)\n",
    "class HfModelId(str, Enum):\n",
    "    # SD ëª¨ë¸\n",
    "    SD_V1_5: str = \"SG161222/Realistic_Vision_V5.1_noVAE\"\n",
    "    SD_VAE: str = \"stabilityai/sd-vae-ft-mse\"\n",
    "    \n",
    "    # SDXL ëª¨ë¸\n",
    "    SDXL_V1_0_BASE: str = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "    SDXL_V1_0_REFINER: str = \"stabilityai/stable-diffusion-xl-refiner-1.0\"\n",
    "\n",
    "ENABLE_MODEL_CPU_OFFLOAD: Final = True\n",
    "USE_REFINER: Final = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db19df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SD ëª¨ë¸ ë¡œë”© í•¨ìˆ˜ë“¤\n",
    "def load_sd_base_model() -> Any:\n",
    "    \"\"\"SD ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë”© (LoRA ì—†ì´)\"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Loading SD base model on device: {device}\")\n",
    "\n",
    "    model = StableDiffusionPipeline.from_pretrained(\n",
    "        HfModelId.SD_V1_5.value, torch_dtype=torch.float16\n",
    "    ).to(device)\n",
    "\n",
    "    model.vae = AutoencoderKL.from_pretrained(\n",
    "        HfModelId.SD_VAE.value, torch_dtype=torch.float16\n",
    "    ).to(device)\n",
    "\n",
    "    model.scheduler = EulerDiscreteScheduler.from_config(\n",
    "        model.scheduler.config, use_karras_sigmas=True\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def load_sd_lora_model(model_dir: str) -> Any:\n",
    "    \"\"\"SD LoRA ëª¨ë¸ ë¡œë”© (ë² ì´ìŠ¤ + LoRA)\"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Loading SD LoRA model on device: {device}\")\n",
    "\n",
    "    model = StableDiffusionPipeline.from_pretrained(\n",
    "        HfModelId.SD_V1_5.value, torch_dtype=torch.float16\n",
    "    ).to(device)\n",
    "\n",
    "    model.vae = AutoencoderKL.from_pretrained(\n",
    "        HfModelId.SD_VAE.value, torch_dtype=torch.float16\n",
    "    ).to(device)\n",
    "\n",
    "    model.scheduler = EulerDiscreteScheduler.from_config(\n",
    "        model.scheduler.config, use_karras_sigmas=True\n",
    "    )\n",
    "\n",
    "    print(f\"Loading LoRA weights from: {model_dir}\")\n",
    "    model.load_lora_weights(model_dir)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0895029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDXL ëª¨ë¸ ë¡œë”© í•¨ìˆ˜ë“¤\n",
    "def load_sdxl_base_model() -> Dict[str, Any]:\n",
    "    \"\"\"SDXL ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë”© (LoRA ì—†ì´)\"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Loading SDXL base model on device: {device}\")\n",
    "\n",
    "    model = DiffusionPipeline.from_pretrained(\n",
    "        HfModelId.SDXL_V1_0_BASE.value,\n",
    "        torch_dtype=torch.float16,\n",
    "        variant=\"fp16\",\n",
    "    )\n",
    "    \n",
    "    _ = (\n",
    "        model.enable_model_cpu_offload()\n",
    "        if ENABLE_MODEL_CPU_OFFLOAD\n",
    "        else model.to(device)\n",
    "    )\n",
    "\n",
    "    return {\"model\": model, \"refiner\": None}\n",
    "\n",
    "def load_sdxl_lora_model(model_dir: str) -> Dict[str, Any]:\n",
    "    \"\"\"SDXL LoRA ëª¨ë¸ ë¡œë”© (ë² ì´ìŠ¤ + LoRA)\"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Loading SDXL LoRA model on device: {device}\")\n",
    "\n",
    "    model = DiffusionPipeline.from_pretrained(\n",
    "        HfModelId.SDXL_V1_0_BASE.value,\n",
    "        torch_dtype=torch.float16,\n",
    "        variant=\"fp16\",\n",
    "    )\n",
    "    \n",
    "    _ = (\n",
    "        model.enable_model_cpu_offload()\n",
    "        if ENABLE_MODEL_CPU_OFFLOAD\n",
    "        else model.to(device)\n",
    "    )\n",
    "\n",
    "    print(f\"Loading LoRA weights from: {model_dir}\")\n",
    "    model.load_lora_weights(model_dir)\n",
    "\n",
    "    return {\"model\": model, \"refiner\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4bbb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜ë“¤\n",
    "def generate_sd_image(model: Any, prompt: str, **kwargs) -> Image.Image:\n",
    "    \"\"\"SD ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„±\"\"\"\n",
    "    height = kwargs.get(\"height\", 512)\n",
    "    width = kwargs.get(\"width\", 512)\n",
    "    num_inference_steps = kwargs.get(\"num_inference_steps\", 50)\n",
    "    guidance_scale = kwargs.get(\"guidance_scale\", 7.5)\n",
    "    negative_prompt = kwargs.get(\"negative_prompt\", None)\n",
    "    num_images_per_prompt = kwargs.get(\"num_images_per_prompt\", 1)\n",
    "    seed = kwargs.get(\"seed\", 42)\n",
    "    cross_attention_scale = kwargs.get(\"cross_attention_scale\", 0.5)\n",
    "\n",
    "    negative_prompt = negative_prompt if negative_prompt and len(negative_prompt) > 0 else None\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    generator = torch.Generator(device=device).manual_seed(seed)\n",
    "    generated_images = model(\n",
    "        prompt,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        guidance_scale=guidance_scale,\n",
    "        negative_prompt=negative_prompt,\n",
    "        num_images_per_prompt=num_images_per_prompt,\n",
    "        generator=generator,\n",
    "        cross_attention_kwargs={\"scale\": cross_attention_scale},\n",
    "    )[\"images\"]\n",
    "\n",
    "    return generated_images[0]\n",
    "\n",
    "def generate_sdxl_image(model_dict: Dict[str, Any], prompt: str, **kwargs) -> Image.Image:\n",
    "    \"\"\"SDXL ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„±\"\"\"\n",
    "    height = kwargs.get(\"height\", 1024)\n",
    "    width = kwargs.get(\"width\", 1024)\n",
    "    num_inference_steps = kwargs.get(\"num_inference_steps\", 50)\n",
    "    guidance_scale = kwargs.get(\"guidance_scale\", 7.5)\n",
    "    negative_prompt = kwargs.get(\"negative_prompt\", None)\n",
    "    num_images_per_prompt = kwargs.get(\"num_images_per_prompt\", 1)\n",
    "    seed = kwargs.get(\"seed\", 42)\n",
    "    high_noise_frac = kwargs.get(\"high_noise_frac\", 0.7)\n",
    "    cross_attention_scale = kwargs.get(\"cross_attention_scale\", 0.5)\n",
    "\n",
    "    negative_prompt = negative_prompt if negative_prompt and len(negative_prompt) > 0 else None\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    model, refiner = model_dict[\"model\"], model_dict[\"refiner\"]\n",
    "    generator = torch.Generator(device=device).manual_seed(seed)\n",
    "\n",
    "    if USE_REFINER and refiner:\n",
    "        image = model(\n",
    "            prompt=prompt,\n",
    "            height=height,\n",
    "            width=width,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            negative_prompt=negative_prompt,\n",
    "            num_images_per_prompt=num_images_per_prompt,\n",
    "            denoising_end=high_noise_frac,\n",
    "            generator=generator,\n",
    "            output_type=\"latent\",\n",
    "            cross_attention_kwargs={\"scale\": cross_attention_scale},\n",
    "        )[\"images\"]\n",
    "        generated_images = refiner(\n",
    "            prompt=prompt,\n",
    "            image=image,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            denoising_start=high_noise_frac,\n",
    "        )[\"images\"]\n",
    "    else:\n",
    "        generated_images = model(\n",
    "            prompt=prompt,\n",
    "            height=height,\n",
    "            width=width,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            negative_prompt=negative_prompt,\n",
    "            num_images_per_prompt=num_images_per_prompt,\n",
    "            generator=generator,\n",
    "            cross_attention_kwargs={\"scale\": cross_attention_scale},\n",
    "        )[\"images\"]\n",
    "\n",
    "    return generated_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d26091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ë¯¸ì§€ ë¹„êµ ì‹œê°í™” í•¨ìˆ˜\n",
    "def compare_images(base_image: Image.Image, lora_image: Image.Image, \n",
    "                  prompt: str, model_type: str = \"SDXL\", \n",
    "                  figsize: Tuple[int, int] = (12, 6)):\n",
    "    \"\"\"ë² ì´ìŠ¤ ëª¨ë¸ê³¼ LoRA ëª¨ë¸ì˜ ì´ë¯¸ì§€ë¥¼ ë‚˜ë€íˆ ë¹„êµí•˜ì—¬ í‘œì‹œ\"\"\"\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "    \n",
    "    # ë² ì´ìŠ¤ ëª¨ë¸ ì´ë¯¸ì§€\n",
    "    ax1.imshow(base_image)\n",
    "    ax1.set_title(f'{model_type} Base Model\\n{prompt[:50]}{\"...\" if len(prompt) > 50 else \"\"}', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # LoRA ëª¨ë¸ ì´ë¯¸ì§€\n",
    "    ax2.imshow(lora_image)\n",
    "    ax2.set_title(f'{model_type} LoRA Model\\n{prompt[:50]}{\"...\" if len(prompt) > 50 else \"\"}', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ì´ë¯¸ì§€ ì •ë³´ ì¶œë ¥\n",
    "    print(f\"\\n=== ì´ë¯¸ì§€ ë¹„êµ ê²°ê³¼ ===\")\n",
    "    print(f\"í”„ë¡¬í”„íŠ¸: {prompt}\")\n",
    "    print(f\"ë² ì´ìŠ¤ ëª¨ë¸ ì´ë¯¸ì§€ í¬ê¸°: {base_image.size}\")\n",
    "    print(f\"LoRA ëª¨ë¸ ì´ë¯¸ì§€ í¬ê¸°: {lora_image.size}\")\n",
    "    print(f\"ëª¨ë¸ íƒ€ì…: {model_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e09093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¤ì •\n",
    "MODEL_TYPE = \"SDXL\"  # \"SD\" ë˜ëŠ” \"SDXL\"\n",
    "LORA_PATH = \"../models/\"  # LoRA ê°€ì¤‘ì¹˜ ê²½ë¡œ\n",
    "\n",
    "print(f\"ëª¨ë¸ íƒ€ì…: {MODEL_TYPE}\")\n",
    "print(f\"LoRA ê²½ë¡œ: {LORA_PATH}\")\n",
    "print(f\"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888904e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ë¡œë”©\n",
    "print(\"=== ëª¨ë¸ ë¡œë”© ì‹œì‘ ===\")\n",
    "\n",
    "if MODEL_TYPE == \"SD\":\n",
    "    # SD ëª¨ë¸ ë¡œë”©\n",
    "    print(\"\\n1. SD ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
    "    sd_base_model = load_sd_base_model()\n",
    "    \n",
    "    print(\"\\n2. SD LoRA ëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
    "    sd_lora_model = load_sd_lora_model(LORA_PATH)\n",
    "    \n",
    "    base_model = sd_base_model\n",
    "    lora_model = sd_lora_model\n",
    "    \n",
    "else:\n",
    "    # SDXL ëª¨ë¸ ë¡œë”©\n",
    "    print(\"\\n1. SDXL ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
    "    sdxl_base_model = load_sdxl_base_model()\n",
    "    \n",
    "    print(\"\\n2. SDXL LoRA ëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
    "    sdxl_lora_model = load_sdxl_lora_model(LORA_PATH)\n",
    "    \n",
    "    base_model = sdxl_base_model\n",
    "    lora_model = sdxl_lora_model\n",
    "\n",
    "print(\"\\n=== ëª¨ë¸ ë¡œë”© ì™„ë£Œ ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ec4900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸\n",
    "test_prompts = [\n",
    "    \"a photo of a woman wearing fashion clothes\",\n",
    "    \"a photo of a fashion model in street style\",\n",
    "    \"a photo of a person wearing trendy outfit\",\n",
    "    \"a photo of a woman in casual fashion\"\n",
    "]\n",
    "\n",
    "# ê¸°ë³¸ íŒŒë¼ë¯¸í„°\n",
    "params = {\n",
    "    \"num_inference_steps\": 30,  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì¤„ì„\n",
    "    \"guidance_scale\": 7.5,\n",
    "    \"seed\": 42,\n",
    "    \"cross_attention_scale\": 0.5\n",
    "}\n",
    "\n",
    "if MODEL_TYPE == \"SD\":\n",
    "    params.update({\"height\": 512, \"width\": 512})\n",
    "else:\n",
    "    params.update({\"height\": 1024, \"width\": 1024})\n",
    "\n",
    "print(f\"í…ŒìŠ¤íŠ¸ íŒŒë¼ë¯¸í„°: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a192fe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²« ë²ˆì§¸ í”„ë¡¬í”„íŠ¸ë¡œ í…ŒìŠ¤íŠ¸\n",
    "prompt = test_prompts[0]\n",
    "print(f\"\\n=== í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸: {prompt} ===\")\n",
    "\n",
    "# ë² ì´ìŠ¤ ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„±\n",
    "print(\"\\n1. ë² ì´ìŠ¤ ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„± ì¤‘...\")\n",
    "if MODEL_TYPE == \"SD\":\n",
    "    base_image = generate_sd_image(base_model, prompt, **params)\n",
    "else:\n",
    "    base_image = generate_sdxl_image(base_model, prompt, **params)\n",
    "\n",
    "# LoRA ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„±\n",
    "print(\"\\n2. LoRA ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„± ì¤‘...\")\n",
    "if MODEL_TYPE == \"SD\":\n",
    "    lora_image = generate_sd_image(lora_model, prompt, **params)\n",
    "else:\n",
    "    lora_image = generate_sdxl_image(lora_model, prompt, **params)\n",
    "\n",
    "# ê²°ê³¼ ë¹„êµ\n",
    "compare_images(base_image, lora_image, prompt, MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98452db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ë¡œ í…ŒìŠ¤íŠ¸\n",
    "for i, prompt in enumerate(test_prompts[1:], 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"í…ŒìŠ¤íŠ¸ {i+1}: {prompt}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # ë² ì´ìŠ¤ ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„±\n",
    "    print(\"ë² ì´ìŠ¤ ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„± ì¤‘...\")\n",
    "    if MODEL_TYPE == \"SD\":\n",
    "        base_image = generate_sd_image(base_model, prompt, **params)\n",
    "    else:\n",
    "        base_image = generate_sdxl_image(base_model, prompt, **params)\n",
    "\n",
    "    # LoRA ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„±\n",
    "    print(\"LoRA ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„± ì¤‘...\")\n",
    "    if MODEL_TYPE == \"SD\":\n",
    "        lora_image = generate_sd_image(lora_model, prompt, **params)\n",
    "    else:\n",
    "        lora_image = generate_sdxl_image(lora_model, prompt, **params)\n",
    "\n",
    "    # ê²°ê³¼ ë¹„êµ\n",
    "    compare_images(base_image, lora_image, prompt, MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc98ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒŒë¼ë¯¸í„° ì‹¤í—˜\n",
    "experiment_prompt = \"a photo of a woman wearing fashion clothes, high quality\"\n",
    "\n",
    "# ë‹¤ì–‘í•œ guidance scale ì‹¤í—˜\n",
    "guidance_scales = [5.0, 7.5, 10.0, 12.5]\n",
    "\n",
    "print(f\"\\n=== Guidance Scale ì‹¤í—˜ ===\")\n",
    "print(f\"í”„ë¡¬í”„íŠ¸: {experiment_prompt}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, guidance in enumerate(guidance_scales):\n",
    "    print(f\"\\nGuidance Scale {guidance}ë¡œ ì´ë¯¸ì§€ ìƒì„± ì¤‘...\")\n",
    "    \n",
    "    # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸\n",
    "    test_params = params.copy()\n",
    "    test_params[\"guidance_scale\"] = guidance\n",
    "    \n",
    "    # LoRA ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„±\n",
    "    if MODEL_TYPE == \"SD\":\n",
    "        image = generate_sd_image(lora_model, experiment_prompt, **test_params)\n",
    "    else:\n",
    "        image = generate_sdxl_image(lora_model, experiment_prompt, **test_params)\n",
    "    \n",
    "    # ì´ë¯¸ì§€ í‘œì‹œ\n",
    "    axes[i].imshow(image)\n",
    "    axes[i].set_title(f'Guidance Scale: {guidance}', fontsize=12, fontweight='bold')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== Guidance Scale ì‹¤í—˜ ì™„ë£Œ ===\")\n",
    "print(\"ë†’ì€ guidance scaleì€ ë” ê°•í•œ í”„ë¡¬í”„íŠ¸ ì¤€ìˆ˜ë¥¼, ë‚®ì€ ê°’ì€ ë” ì°½ì˜ì ì¸ ê²°ê³¼ë¥¼ ë§Œë“­ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bae8a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Attention Scale ì‹¤í—˜\n",
    "cross_attention_scales = [0.3, 0.5, 0.7, 1.0]\n",
    "\n",
    "print(f\"\\n=== Cross Attention Scale ì‹¤í—˜ ===\")\n",
    "print(f\"í”„ë¡¬í”„íŠ¸: {experiment_prompt}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, scale in enumerate(cross_attention_scales):\n",
    "    print(f\"\\nCross Attention Scale {scale}ë¡œ ì´ë¯¸ì§€ ìƒì„± ì¤‘...\")\n",
    "    \n",
    "    # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸\n",
    "    test_params = params.copy()\n",
    "    test_params[\"cross_attention_scale\"] = scale\n",
    "    \n",
    "    # LoRA ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„±\n",
    "    if MODEL_TYPE == \"SD\":\n",
    "        image = generate_sd_image(lora_model, experiment_prompt, **test_params)\n",
    "    else:\n",
    "        image = generate_sdxl_image(lora_model, experiment_prompt, **test_params)\n",
    "    \n",
    "    # ì´ë¯¸ì§€ í‘œì‹œ\n",
    "    axes[i].imshow(image)\n",
    "    axes[i].set_title(f'Cross Attention Scale: {scale}', fontsize=12, fontweight='bold')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== Cross Attention Scale ì‹¤í—˜ ì™„ë£Œ ===\")\n",
    "print(\"ë†’ì€ cross attention scaleì€ LoRA ê°€ì¤‘ì¹˜ì˜ ì˜í–¥ì„ ë” ê°•í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d233832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ ì‹¤í—˜\n",
    "base_prompt = \"a photo of a woman wearing fashion clothes\"\n",
    "negative_prompts = [\n",
    "    \"\",\n",
    "    \"blurry, low quality\",\n",
    "    \"blurry, low quality, distorted, ugly\",\n",
    "    \"blurry, low quality, distorted, ugly, bad anatomy, extra limbs\"\n",
    "]\n",
    "\n",
    "print(f\"\\n=== ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ ì‹¤í—˜ ===\")\n",
    "print(f\"ë² ì´ìŠ¤ í”„ë¡¬í”„íŠ¸: {base_prompt}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, neg_prompt in enumerate(negative_prompts):\n",
    "    print(f\"\\në„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸: '{neg_prompt}'ë¡œ ì´ë¯¸ì§€ ìƒì„± ì¤‘...\")\n",
    "    \n",
    "    # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸\n",
    "    test_params = params.copy()\n",
    "    test_params[\"negative_prompt\"] = neg_prompt\n",
    "    \n",
    "    # LoRA ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„±\n",
    "    if MODEL_TYPE == \"SD\":\n",
    "        image = generate_sd_image(lora_model, base_prompt, **test_params)\n",
    "    else:\n",
    "        image = generate_sdxl_image(lora_model, base_prompt, **test_params)\n",
    "    \n",
    "    # ì´ë¯¸ì§€ í‘œì‹œ\n",
    "    axes[i].imshow(image)\n",
    "    neg_prompt_display = neg_prompt if neg_prompt else \"(ì—†ìŒ)\"\n",
    "    axes[i].set_title(f'Negative: {neg_prompt_display[:30]}{\"...\" if len(neg_prompt_display) > 30 else \"\"}', \n",
    "                      fontsize=10, fontweight='bold')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ ì‹¤í—˜ ì™„ë£Œ ===\")\n",
    "print(\"ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ëŠ” ì›í•˜ì§€ ì•ŠëŠ” ìš”ì†Œë“¤ì„ ì œê±°í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92805fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜\n",
    "def test_custom_prompt(prompt: str, negative_prompt: str = \"\", \n",
    "                      guidance_scale: float = 7.5, \n",
    "                      cross_attention_scale: float = 0.5):\n",
    "    \"\"\"ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ë¡œ ë² ì´ìŠ¤ ëª¨ë¸ê³¼ LoRA ëª¨ë¸ ë¹„êµ\"\"\"\n",
    "    \n",
    "    print(f\"\\n=== ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ ===\")\n",
    "    print(f\"í”„ë¡¬í”„íŠ¸: {prompt}\")\n",
    "    print(f\"ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸: {negative_prompt if negative_prompt else '(ì—†ìŒ)'}\")\n",
    "    \n",
    "    # íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "    test_params = params.copy()\n",
    "    test_params.update({\n",
    "        \"guidance_scale\": guidance_scale,\n",
    "        \"cross_attention_scale\": cross_attention_scale,\n",
    "        \"negative_prompt\": negative_prompt\n",
    "    })\n",
    "    \n",
    "    # ë² ì´ìŠ¤ ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„±\n",
    "    print(\"\\n1. ë² ì´ìŠ¤ ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„± ì¤‘...\")\n",
    "    if MODEL_TYPE == \"SD\":\n",
    "        base_image = generate_sd_image(base_model, prompt, **test_params)\n",
    "    else:\n",
    "        base_image = generate_sdxl_image(base_model, prompt, **test_params)\n",
    "\n",
    "    # LoRA ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„±\n",
    "    print(\"\\n2. LoRA ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„± ì¤‘...\")\n",
    "    if MODEL_TYPE == \"SD\":\n",
    "        lora_image = generate_sd_image(lora_model, prompt, **test_params)\n",
    "    else:\n",
    "        lora_image = generate_sdxl_image(lora_model, prompt, **test_params)\n",
    "\n",
    "    # ê²°ê³¼ ë¹„êµ\n",
    "    compare_images(base_image, lora_image, prompt, MODEL_TYPE)\n",
    "    \n",
    "    return base_image, lora_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dd018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì‹œ: ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸\n",
    "# ì•„ë˜ í”„ë¡¬í”„íŠ¸ë¥¼ ì›í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³€ê²½í•˜ì—¬ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”\n",
    "\n",
    "custom_prompt = \"a photo of a woman wearing elegant dress in urban setting\"\n",
    "custom_negative = \"blurry, low quality, distorted\"\n",
    "\n",
    "base_img, lora_img = test_custom_prompt(\n",
    "    prompt=custom_prompt,\n",
    "    negative_prompt=custom_negative,\n",
    "    guidance_scale=8.0,\n",
    "    cross_attention_scale=0.6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ad2d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„±ëŠ¥ ë¶„ì„ ìš”ì•½\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ¯ LoRA ëª¨ë¸ ì„±ëŠ¥ ë¶„ì„ ìš”ì•½\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nğŸ“Š ì£¼ìš” ê´€ì°°ì‚¬í•­:\")\n",
    "print(\"1. ë² ì´ìŠ¤ ëª¨ë¸ vs LoRA ëª¨ë¸ ë¹„êµ\")\n",
    "print(\"   - ë² ì´ìŠ¤ ëª¨ë¸: ì¼ë°˜ì ì¸ íŒ¨ì…˜ ì´ë¯¸ì§€ ìƒì„±\")\n",
    "print(\"   - LoRA ëª¨ë¸: í›ˆë ¨ ë°ì´í„°ì— íŠ¹í™”ëœ ìŠ¤íƒ€ì¼ ìƒì„±\")\n",
    "\n",
    "print(\"\\n2. íŒŒë¼ë¯¸í„° ì˜í–¥:\")\n",
    "print(\"   - Guidance Scale: ë†’ì„ìˆ˜ë¡ í”„ë¡¬í”„íŠ¸ ì¤€ìˆ˜ë„ ì¦ê°€\")\n",
    "print(\"   - Cross Attention Scale: ë†’ì„ìˆ˜ë¡ LoRA ì˜í–¥ ì¦ê°€\")\n",
    "print(\"   - Negative Prompt: ì´ë¯¸ì§€ í’ˆì§ˆ ê°œì„ ì— ë„ì›€\")\n",
    "\n",
    "print(\"\\n3. ìµœì  íŒŒë¼ë¯¸í„° ì¶”ì²œ:\")\n",
    "print(f\"   - Guidance Scale: 7.5-10.0\")\n",
    "print(f\"   - Cross Attention Scale: 0.5-0.7\")\n",
    "print(f\"   - Steps: 30-50 (í…ŒìŠ¤íŠ¸ìš©/í’ˆì§ˆìš©)\")\n",
    "\n",
    "print(\"\\n4. ì‚¬ìš© íŒ:\")\n",
    "print(\"   - íŒ¨ì…˜ ê´€ë ¨ í”„ë¡¬í”„íŠ¸ì—ì„œ LoRA íš¨ê³¼ê°€ ê°€ì¥ ëšœë ·í•¨\")\n",
    "print(\"   - ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ë¡œ í’ˆì§ˆ ê°œì„  ê°€ëŠ¥\")\n",
    "print(\"   - ë‹¤ì–‘í•œ íŒŒë¼ë¯¸í„° ì¡°í•©ìœ¼ë¡œ ì‹¤í—˜ ê¶Œì¥\")\n",
    "\n",
    "print(\"\\nâœ… LoRA ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ í›ˆë ¨ë˜ì—ˆìœ¼ë©°, ë² ì´ìŠ¤ ëª¨ë¸ ëŒ€ë¹„ íŠ¹í™”ëœ ìŠ¤íƒ€ì¼ì„ ìƒì„±í•©ë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47637f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ë¯¸ì§€ ì €ì¥ í•¨ìˆ˜\n",
    "def save_comparison_images(base_image: Image.Image, lora_image: Image.Image, \n",
    "                          prompt: str, model_type: str = \"SDXL\", \n",
    "                          save_dir: str = \"../generated_comparisons/\"):\n",
    "    \"\"\"ë¹„êµ ì´ë¯¸ì§€ë“¤ì„ ì €ì¥\"\"\"\n",
    "    \n",
    "    # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # íŒŒì¼ëª… ìƒì„±\n",
    "    safe_prompt = prompt[:30].replace(' ', '_').replace(',', '')\n",
    "    timestamp = str(int(torch.rand(1).item() * 10000))\n",
    "    \n",
    "    base_filename = f\"{save_dir}{model_type}_base_{safe_prompt}_{timestamp}.png\"\n",
    "    lora_filename = f\"{save_dir}{model_type}_lora_{safe_prompt}_{timestamp}.png\"\n",
    "    \n",
    "    # ì´ë¯¸ì§€ ì €ì¥\n",
    "    base_image.save(base_filename)\n",
    "    lora_image.save(lora_filename)\n",
    "    \n",
    "    print(f\"\\nğŸ’¾ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ:\")\n",
    "    print(f\"   ë² ì´ìŠ¤ ëª¨ë¸: {base_filename}\")\n",
    "    print(f\"   LoRA ëª¨ë¸: {lora_filename}\")\n",
    "    \n",
    "    return base_filename, lora_filename\n",
    "\n",
    "# ì˜ˆì‹œ: ë§ˆì§€ë§‰ ìƒì„±ëœ ì´ë¯¸ì§€ë“¤ ì €ì¥\n",
    "if 'base_img' in locals() and 'lora_img' in locals():\n",
    "    save_comparison_images(base_img, lora_img, custom_prompt, MODEL_TYPE)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
