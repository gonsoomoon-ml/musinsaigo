#!/usr/bin/env python3
"""
Standalone Image Outpainting Script for Musinsaigo
ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë¬´ì‹ ì‚¬ íŒ¨ì…˜ ì´ë¯¸ì§€ë“¤ì„ AIë¡œ í™•ì¥í•˜ì—¬ ì •ì‚¬ê°í˜• ì´ë¯¸ì§€ë¡œ ë§Œë“­ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python outpaint.py --input-dir /path/to/raw_dataset --output-dir /path/to/proc_dataset
"""

import argparse
import json
import os
import sys
from shutil import copyfile
from typing import Final, Optional
import numpy as np
import torch
from diffusers import StableDiffusionInpaintPipeline
from PIL import Image
from tqdm import tqdm
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('outpaint.log')
    ]
)
logger = logging.getLogger(__name__)

# ëª¨ë¸ ìƒì„± ì„¤ì •
MODEL_GEN_CONFIG: Final = {
    "num_inference_steps": 30,
    "guidance_scale": 7.5,
    "negative_prompt": "other people in the background",
    "seed": 42,
}

# ëª¨ë¸ ID
SD_INPAINT_MODEL = "runwayml/stable-diffusion-inpainting"


def arg_as_bool(value):
    """ë¬¸ìì—´ì„ booleanìœ¼ë¡œ ë³€í™˜"""
    if isinstance(value, bool):
        return value
    if value.lower() in ("yes", "true", "t", "y", "1"):
        return True
    if value.lower() in ("no", "false", "f", "n", "0"):
        return False
    raise argparse.ArgumentTypeError(f"Boolean value expected, got {value}")


def get_loc(src_len: int, tgt_len: int) -> int:
    """ì´ë¯¸ì§€ë¥¼ ì¤‘ì•™ì— ë°°ì¹˜í•˜ê¸° ìœ„í•œ ìœ„ì¹˜ ê³„ì‚°"""
    return round((src_len - tgt_len) // 2)


def outpaint_images(
    input_dir: str,
    output_dir: str,
    images_prefix: str = "images",
    outpaint_prompt: str = "",
    resolution: int = 1024,
    run_compile: bool = False,
    num_inference_steps: Optional[int] = None,
    guidance_scale: Optional[float] = None,
    negative_prompt: Optional[str] = None,
    seed: Optional[int] = None,
    max_images: Optional[int] = None,  # í…ŒìŠ¤íŠ¸ìš© ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜
) -> None:
    """
    ì´ë¯¸ì§€ë“¤ì„ outpaintingí•˜ì—¬ ì •ì‚¬ê°í˜•ìœ¼ë¡œ í™•ì¥
    
    Args:
        input_dir: ì›ë³¸ ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ (raw_dataset)
        output_dir: ì¶œë ¥ ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ (proc_dataset)
        images_prefix: ì´ë¯¸ì§€ í´ë”ëª… (ê¸°ë³¸ê°’: "images")
        outpaint_prompt: í™•ì¥í•  ë‚´ìš© í”„ë¡¬í”„íŠ¸
        resolution: ìµœì¢… í•´ìƒë„ (ê¸°ë³¸ê°’: 1024)
        run_compile: PyTorch ì»´íŒŒì¼ ì‚¬ìš© ì—¬ë¶€
        num_inference_steps: ì¶”ë¡  ë‹¨ê³„ ìˆ˜
        guidance_scale: í”„ë¡¬í”„íŠ¸ ì¤€ìˆ˜ ê°•ë„
        negative_prompt: ì œì™¸í•  ë‚´ìš©
        seed: ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ
        max_images: í…ŒìŠ¤íŠ¸ìš© ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜
    """
    
    # ë””ë ‰í† ë¦¬ ì„¤ì •
    raw_images_dir = os.path.join(input_dir, images_prefix)
    proc_images_dir = os.path.join(output_dir, images_prefix)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(proc_images_dir, exist_ok=True)
    
    # ë©”íƒ€ë°ì´í„° íŒŒì¼ ê²½ë¡œ
    raw_metadata_path = os.path.join(input_dir, "metadata.jsonl")
    proc_metadata_path = os.path.join(output_dir, "metadata.jsonl")
    
    # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    device = "cuda" if torch.cuda.is_available() else "cpu"
    logger.info(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    if device == "cpu":
        logger.warning("GPUê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. CPUì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤ (ëŠë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤).")
    
    # ëª¨ë¸ ë¡œë“œ
    logger.info("Stable Diffusion Inpainting ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
    model = StableDiffusionInpaintPipeline.from_pretrained(
        SD_INPAINT_MODEL,
        torch_dtype=torch.float16,
    ).to(device)
    
    # PyTorch ì»´íŒŒì¼ (ì„ íƒì‚¬í•­)
    if run_compile:
        logger.info("PyTorch ì»´íŒŒì¼ì„ ì ìš©í•©ë‹ˆë‹¤...")
        model.unet.to(memory_format=torch.channels_last)
        torch.compile(model.unet, mode="reduce-overhead", fullgraph=True)
    
    # ìƒì„±ê¸° ì„¤ì •
    generator = torch.Generator(device=device).manual_seed(seed or MODEL_GEN_CONFIG["seed"])
    
    # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ìƒì„±
    logger.info("ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤...")
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']
    image_files = []
    
    if os.path.exists(raw_images_dir):
        for filename in os.listdir(raw_images_dir):
            if any(filename.lower().endswith(ext) for ext in image_extensions):
                image_files.append(filename)
    
    if not image_files:
        logger.error(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {raw_images_dir}")
        return
    
    # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜ ì œí•œ
    if max_images:
        image_files = image_files[:max_images]
        logger.info(f"í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {max_images}ê°œ ì´ë¯¸ì§€ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    
    total_images = len(image_files)
    logger.info(f"ì´ {total_images}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    
    # ì´ë¯¸ì§€ outpainting ì‹œì‘
    logger.info("ì´ë¯¸ì§€ outpaintingì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    processed_count = 0
    error_count = 0
    processed_metadata = []
    
    for filename in tqdm(image_files, total=total_images, desc="Outpainting ì§„í–‰ë¥ "):
        try:
            # í”„ë¡¬í”„íŠ¸ ì„¤ì • (outpaint_promptê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
            prompt = outpaint_prompt if len(outpaint_prompt) > 0 else "a photo of a person (people)"
            
            # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
            src_image_path = os.path.join(raw_images_dir, filename)
            if not os.path.exists(src_image_path):
                logger.warning(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {src_image_path}")
                error_count += 1
                continue
            
            src_image = Image.open(src_image_path).convert("RGB")
            src_image_size = np.array(src_image).shape
            
            # ì •ì‚¬ê°í˜• í¬ê¸° ê³„ì‚°
            max_len = max(src_image_size[0], src_image_size[1])
            tgt_image_size = max_len, max_len
            
            # RGBA ì´ë¯¸ì§€ ìƒì„± (íˆ¬ëª… ë°°ê²½)
            rgba_image = Image.new(mode="RGBA", size=tgt_image_size)
            
            # ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì¤‘ì•™ì— ë°°ì¹˜
            Image.Image.paste(
                rgba_image,
                src_image,
                (
                    get_loc(tgt_image_size[1], src_image_size[1]),
                    get_loc(tgt_image_size[0], src_image_size[0]),
                ),
            )
            
            # RGBë¡œ ë³€í™˜
            rgb_image = rgba_image.convert("RGB")
            
            # ë§ˆìŠ¤í¬ ìƒì„± (íˆ¬ëª… ì˜ì—­ì„ ë§ˆìŠ¤í¬ë¡œ ì„¤ì •)
            full_mask = np.array(rgba_image)[:, :, 3] == 0
            full_mask = full_mask.astype(np.uint8) * 255
            full_mask = np.dstack([np.array(full_mask)] * 3)
            mask_image = Image.fromarray(full_mask)
            
            # Outpainting ì‹¤í–‰
            tgt_image = model(
                prompt=prompt,
                height=resolution,
                width=resolution,
                image=rgb_image.resize((resolution, resolution)),
                mask_image=mask_image.resize((resolution, resolution)),
                generator=generator,
                num_inference_steps=num_inference_steps or MODEL_GEN_CONFIG["num_inference_steps"],
                guidance_scale=guidance_scale or MODEL_GEN_CONFIG["guidance_scale"],
                negative_prompt=negative_prompt or MODEL_GEN_CONFIG["negative_prompt"],
            ).images[0]
            
            # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° ê³„ì‚°
            tgt_image_size = round(
                resolution * src_image_size[0] / tgt_image_size[0]
            ), round(resolution * src_image_size[1] / tgt_image_size[1])
            
            # ìƒì„±ëœ ì´ë¯¸ì§€ì— ì›ë³¸ ì´ë¯¸ì§€ ë³µì›
            Image.Image.paste(
                tgt_image,
                src_image.resize(
                    (
                        tgt_image_size[1],
                        tgt_image_size[0],
                    )
                ),
                (
                    get_loc(resolution, tgt_image_size[1]),
                    get_loc(resolution, tgt_image_size[0]),
                ),
            )
            
            # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
            output_image_path = os.path.join(proc_images_dir, filename)
            tgt_image.save(output_image_path)
            
            # ë©”íƒ€ë°ì´í„° ìƒì„±
            metadata = {
                "file_name": f"{images_prefix}/{filename}",
                "text": prompt
            }
            processed_metadata.append(metadata)
            
            processed_count += 1
            
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({filename}): {e}")
            error_count += 1
            continue
    
    # ë©”íƒ€ë°ì´í„° íŒŒì¼ ì €ì¥
    with open(proc_metadata_path, "w", encoding="utf-8") as output_file:
        for metadata in processed_metadata:
            output_file.write(json.dumps(metadata, ensure_ascii=False) + "\n")
    
    # ê²°ê³¼ ìš”ì•½
    logger.info("=" * 50)
    logger.info(" Outpainting ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    logger.info(f"âœ… ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {processed_count}ê°œ")
    if error_count > 0:
        logger.warning(f"âš ï¸ ì²˜ë¦¬ ì‹¤íŒ¨í•œ ì´ë¯¸ì§€: {error_count}ê°œ")
    logger.info(f"ğŸ“ ì…ë ¥ ë””ë ‰í† ë¦¬: {input_dir}")
    logger.info(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    logger.info(f"ğŸ–¼ï¸ í•´ìƒë„: {resolution}x{resolution}")
    logger.info(f"ğŸ¯ í”„ë¡¬í”„íŠ¸: {outpaint_prompt if outpaint_prompt else 'ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©'}")
    if max_images:
        logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {max_images}ê°œ ì´ë¯¸ì§€ ì œí•œ")
    logger.info("=" * 50)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="ë¬´ì‹ ì‚¬ íŒ¨ì…˜ ì´ë¯¸ì§€ Outpainting ìŠ¤í¬ë¦½íŠ¸",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰
  python outpaint.py --input-dir /path/to/raw_dataset --output-dir /path/to/proc_dataset
  
  # í…ŒìŠ¤íŠ¸ìš© (2ê°œ ì´ë¯¸ì§€ë§Œ)
  python outpaint.py --input-dir /path/to/raw_dataset --output-dir /path/to/proc_dataset --max-images 2
  
  # ì»¤ìŠ¤í…€ ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰
  python outpaint.py \\
    --input-dir /path/to/raw_dataset \\
    --output-dir /path/to/proc_dataset \\
    --resolution 1024 \\
    --outpaint-prompt "a photo of a person (people)" \\
    --num-inference-steps 50 \\
    --guidance-scale 7.5
        """
    )
    
    # í•„ìˆ˜ ì¸ì
    parser.add_argument(
        "--input-dir", 
        type=str, 
        required=True,
        help="ì›ë³¸ ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ (raw_dataset)"
    )
    parser.add_argument(
        "--output-dir", 
        type=str, 
        required=True,
        help="ì¶œë ¥ ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ (proc_dataset)"
    )
    
    # ì„ íƒì  ì¸ì
    parser.add_argument(
        "--images-prefix", 
        type=str, 
        default="images",
        help="ì´ë¯¸ì§€ í´ë”ëª… (ê¸°ë³¸ê°’: images)"
    )
    parser.add_argument(
        "--outpaint-prompt", 
        type=str, 
        default="",
        help="í™•ì¥í•  ë‚´ìš© í”„ë¡¬í”„íŠ¸ (ê¸°ë³¸ê°’: ì›ë³¸ ìº¡ì…˜ ì‚¬ìš©)"
    )
    parser.add_argument(
        "--resolution", 
        type=int, 
        default=1024,
        help="ìµœì¢… í•´ìƒë„ (ê¸°ë³¸ê°’: 1024)"
    )
    parser.add_argument(
        "--run-compile", 
        type=arg_as_bool, 
        default=False,
        help="PyTorch ì»´íŒŒì¼ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: False)"
    )
    
    # ëª¨ë¸ ì„¤ì • ì¸ì
    parser.add_argument(
        "--num-inference-steps", 
        type=int, 
        default=30,
        help="ì¶”ë¡  ë‹¨ê³„ ìˆ˜ (ê¸°ë³¸ê°’: 30)"
    )
    parser.add_argument(
        "--guidance-scale", 
        type=float, 
        default=7.5,
        help="í”„ë¡¬í”„íŠ¸ ì¤€ìˆ˜ ê°•ë„ (ê¸°ë³¸ê°’: 7.5)"
    )
    parser.add_argument(
        "--negative-prompt", 
        type=str, 
        default="other people in the background",
        help="ì œì™¸í•  ë‚´ìš© (ê¸°ë³¸ê°’: other people in the background)"
    )
    parser.add_argument(
        "--seed", 
        type=int, 
        default=42,
        help="ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ (ê¸°ë³¸ê°’: 42)"
    )
    
    # í…ŒìŠ¤íŠ¸ìš© ì¸ì
    parser.add_argument(
        "--max-images", 
        type=int, 
        default=None,
        help="í…ŒìŠ¤íŠ¸ìš© ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜ (ê¸°ë³¸ê°’: ëª¨ë“  ì´ë¯¸ì§€)"
    )
    
    args = parser.parse_args()
    
    # ì…ë ¥ ë””ë ‰í† ë¦¬ í™•ì¸
    if not os.path.exists(args.input_dir):
        logger.error(f"ì…ë ¥ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {args.input_dir}")
        sys.exit(1)
    
    # ë©”íƒ€ë°ì´í„° íŒŒì¼ í™•ì¸
    metadata_path = os.path.join(args.input_dir, "metadata.jsonl")
    if not os.path.exists(metadata_path):
        logger.error(f"ë©”íƒ€ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {metadata_path}")
        sys.exit(1)
    
    logger.info(" ë¬´ì‹ ì‚¬ íŒ¨ì…˜ ì´ë¯¸ì§€ Outpaintingì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    logger.info(f"ğŸ“ ì…ë ¥ ë””ë ‰í† ë¦¬: {args.input_dir}")
    logger.info(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {args.output_dir}")
    logger.info(f"ğŸ–¼ï¸ í•´ìƒë„: {args.resolution}x{args.resolution}")
    logger.info(f"ğŸ¯ í”„ë¡¬í”„íŠ¸: {args.outpaint_prompt if args.outpaint_prompt else 'ì›ë³¸ ìº¡ì…˜ ì‚¬ìš©'}")
    if args.max_images:
        logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {args.max_images}ê°œ ì´ë¯¸ì§€ ì œí•œ")
    
    # Outpainting ì‹¤í–‰
    outpaint_images(
        input_dir=args.input_dir,
        output_dir=args.output_dir,
        images_prefix=args.images_prefix,
        outpaint_prompt=args.outpaint_prompt,
        resolution=args.resolution,
        run_compile=args.run_compile,
        num_inference_steps=args.num_inference_steps,
        guidance_scale=args.guidance_scale,
        negative_prompt=args.negative_prompt,
        seed=args.seed,
        max_images=args.max_images,
    )


if __name__ == "__main__":
    main()
